{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07_Feature_Selection.py\n",
        "\n",
        "This notebook was automatically converted from a Python script."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dbb882c",
      "metadata": {},
      "source": [
        "Feature Selection with Scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import (\n",
        "    SelectKBest, \n",
        "    f_classif, \n",
        "    chi2, \n",
        "    RFE, \n",
        "    SelectFromModel,\n",
        "    mutual_info_classif,\n",
        "    VarianceThreshold\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set random seed for reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save figures in the same directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGES_DIR = './'\n",
        "\n",
        "print(\"# 1. Introduction to Feature Selection\")\n",
        "print(\"Feature selection is the process of selecting a subset of relevant features for use in model construction.\")\n",
        "print(\"It helps in reducing overfitting, improving accuracy, and reducing training time.\")\n",
        "print(\"In this notebook, we'll explore various feature selection techniques in scikit-learn.\")\n",
        "\n",
        "print(\"\\n# 2. Dataset Preparation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load breast cancer dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Feature names: {feature_names}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data into train and test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardize features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n# 3. Filter Methods\")\n",
        "print(\"Filter methods select features based on statistical measures, independent of any ML algorithm.\")\n",
        "\n",
        "print(\"\\n## 3.1 Variance Threshold\")\n",
        "print(\"Removes features with low variance.\")\n",
        "selector = VarianceThreshold(threshold=0.1)\n",
        "X_train_var = selector.fit_transform(X_train_scaled)\n",
        "X_test_var = selector.transform(X_test_scaled)\n",
        "\n",
        "var_support = selector.get_support()\n",
        "var_features = feature_names[var_support]\n",
        "print(f\"Number of selected features: {len(var_features)}\")\n",
        "print(f\"Selected features: {var_features}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train model on selected features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_var, y_train)\n",
        "y_pred = model.predict(X_test_var)\n",
        "print(f\"Accuracy with variance threshold: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "print(\"\\n## 3.2 SelectKBest with F-score\")\n",
        "print(\"Selects features based on univariate statistical tests.\")\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "X_train_k = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_k = selector.transform(X_test_scaled)\n",
        "\n",
        "scores = selector.scores_\n",
        "features_scores = list(zip(feature_names, scores))\n",
        "features_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 10 features based on F-score:\")\n",
        "for feature, score in features_scores[:10]:\n",
        "    print(f\"{feature}: {score:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "top_features = [x[0] for x in features_scores[:10]]\n",
        "top_scores = [x[1] for x in features_scores[:10]]\n",
        "plt.barh(range(10), top_scores, align='center')\n",
        "plt.yticks(range(10), top_features)\n",
        "plt.xlabel('F-Score')\n",
        "plt.title('Top 10 Features by F-Score')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{IMAGES_DIR}f_score_feature_importance.png\")\n",
        "plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train model on selected features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_k, y_train)\n",
        "y_pred = model.predict(X_test_k)\n",
        "print(f\"Accuracy with SelectKBest (F-score): {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "print(\"\\n## 3.3 SelectKBest with Mutual Information\")\n",
        "print(\"Selects features based on mutual information between features and target.\")\n",
        "selector = SelectKBest(mutual_info_classif, k=10)\n",
        "X_train_mi = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_mi = selector.transform(X_test_scaled)\n",
        "\n",
        "scores = selector.scores_\n",
        "features_scores = list(zip(feature_names, scores))\n",
        "features_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 10 features based on Mutual Information:\")\n",
        "for feature, score in features_scores[:10]:\n",
        "    print(f\"{feature}: {score:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train model on selected features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_mi, y_train)\n",
        "y_pred = model.predict(X_test_mi)\n",
        "print(f\"Accuracy with SelectKBest (Mutual Information): {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "print(\"\\n# 4. Wrapper Methods\")\n",
        "print(\"Wrapper methods use a ML algorithm to evaluate different subsets of features.\")\n",
        "\n",
        "print(\"\\n## 4.1 Recursive Feature Elimination (RFE)\")\n",
        "print(\"Recursively removes features by training a model and removing the weakest features.\")\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "rfe = RFE(estimator=model, n_features_to_select=10, step=1)\n",
        "X_train_rfe = rfe.fit_transform(X_train_scaled, y_train)\n",
        "X_test_rfe = rfe.transform(X_test_scaled)\n",
        "\n",
        "rfe_support = rfe.get_support()\n",
        "rfe_features = feature_names[rfe_support]\n",
        "print(f\"Selected features: {rfe_features}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train model on selected features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train_rfe, y_train)\n",
        "y_pred = model.predict(X_test_rfe)\n",
        "print(f\"Accuracy with RFE: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "print(\"\\n# 5. Embedded Methods\")\n",
        "print(\"Embedded methods perform feature selection as part of the model training process.\")\n",
        "\n",
        "print(\"\\n## 5.1 Feature Importance with Random Forest\")\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "forest.fit(X_train_scaled, y_train)\n",
        "importances = forest.feature_importances_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sort feature importances and get indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indices = np.argsort(importances)[::-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the feature ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(10):\n",
        "    print(f\"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot feature importances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(10), importances[indices[:10]], align=\"center\")\n",
        "plt.xticks(range(10), feature_names[indices[:10]], rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{IMAGES_DIR}rf_feature_importance.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n## 5.2 SelectFromModel\")\n",
        "print(\"Uses a model's feature importances to select features.\")\n",
        "selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
        "X_train_sfm = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_sfm = selector.transform(X_test_scaled)\n",
        "\n",
        "sfm_support = selector.get_support()\n",
        "sfm_features = feature_names[sfm_support]\n",
        "print(f\"Number of selected features: {len(sfm_features)}\")\n",
        "print(f\"Selected features: {sfm_features}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train model on selected features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_sfm, y_train)\n",
        "y_pred = model.predict(X_test_sfm)\n",
        "print(f\"Accuracy with SelectFromModel: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "print(\"\\n# 6. Comparing Different Feature Selection Methods\")\n",
        "print(\"Let's compare the performance of different feature selection methods.\")\n",
        "print(\"We'll use a simple benchmark: a logistic regression model trained on features selected by each method.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a synthetic dataset for comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_syn, y_syn = make_classification(n_samples=1000, n_features=20, n_informative=10, \n",
        "                                   n_redundant=5, n_repeated=0, n_classes=2, \n",
        "                                   random_state=42)\n",
        "\n",
        "X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
        "    X_syn, y_syn, test_size=0.3, random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define feature selection methods to compare\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "methods = {\n",
        "    'Variance Threshold': VarianceThreshold(threshold=0.01),\n",
        "    'SelectKBest (F-score)': SelectKBest(f_classif, k=10),\n",
        "    'SelectKBest (Mutual Info)': SelectKBest(mutual_info_classif, k=10),\n",
        "    'RFE': RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=10),\n",
        "    'SelectFromModel (RF)': SelectFromModel(\n",
        "        RandomForestClassifier(n_estimators=100, random_state=42), max_features=10\n",
        "    )\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, method in methods.items():\n",
        "    # Select features\n",
        "    X_train_selected = method.fit_transform(X_train_syn, y_train_syn)\n",
        "    X_test_selected = method.transform(X_test_syn)\n",
        "    \n",
        "    # Train and evaluate model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_selected, y_train_syn)\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    accuracy = accuracy_score(y_test_syn, y_pred)\n",
        "    \n",
        "    results[name] = accuracy\n",
        "    print(f\"{name}: Accuracy = {accuracy:.4f}, Features = {X_train_selected.shape[1]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "methods = list(results.keys())\n",
        "accuracies = list(results.values())\n",
        "plt.bar(methods, accuracies)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Feature Selection Methods')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{IMAGES_DIR}feature_selection_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n# 7. Best Practices and Considerations\")\n",
        "print(\"When applying feature selection:\")\n",
        "print(\"- Always split your data before feature selection to prevent data leakage\")\n",
        "print(\"- Consider the nature of your data when choosing a selection method\")\n",
        "print(\"- Remember that correlation ≠ causation\")\n",
        "print(\"- Use domain knowledge when available\")\n",
        "print(\"- Try multiple feature selection methods and compare results\")\n",
        "print(\"- Beware of multicollinearity between features\")\n",
        "\n",
        "print(\"\\n# 8. Conclusion\")\n",
        "print(\"Feature selection is a crucial step in the machine learning pipeline.\")\n",
        "print(\"It can improve model performance, reduce overfitting, and decrease training time.\")\n",
        "print(\"Scikit-learn provides a comprehensive set of tools for feature selection.\")\n",
        "print(\"The best method depends on your specific dataset and problem.\") \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
